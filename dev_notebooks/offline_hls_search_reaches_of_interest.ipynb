{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from pystac_client import Client  \n",
    "# from collections import defaultdict    \n",
    "# import json\n",
    "# import geopandas\n",
    "# from cartopy import crs\n",
    "import geopandas as gpd\n",
    "# import glob\n",
    "# import netCDF4\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, shape\n",
    "from itertools import repeat\n",
    "import netCDF4 as ncf\n",
    "from itertools import chain\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "# # Local importse\n",
    "# from datagen.S3List import S3List\n",
    "\n",
    "\n",
    "def generate_time_search(timekey):\n",
    "        # timekey = \"2024-01-01T00:00:00Z,2024-04-01T23:59:59Z\"\n",
    "        time1 = timekey.split(',')[0].split('T')[0]\n",
    "        all_date = [int(i) for i in time1.split('-')]\n",
    "        time2 = timekey.split(',')[1].split('T')[0]\n",
    "        final_hours = [i for i in timekey.split(',')[1].split('T')[1].split(':')]\n",
    "        all_date2 = [int(i) for i in time2.split('-')]\n",
    "\n",
    "\n",
    "        start_date = datetime(all_date[0], all_date[1], all_date[2])\n",
    "        end_date = datetime(all_date2[0], all_date2[1], all_date2[2])\n",
    "\n",
    "        add_days = timedelta(days=30)\n",
    "        add_ending_hours = timedelta(hours = int(final_hours[0]), minutes=int(final_hours[1]), seconds=int(final_hours[2][:-1]))\n",
    "\n",
    "\n",
    "        start_dates = []\n",
    "        ending_dates = []\n",
    "\n",
    "        while start_date <= end_date:\n",
    "            start_dates.append(start_date)\n",
    "            start_date += add_days\n",
    "            ending_dates.append(start_date)\n",
    "\n",
    "        ending_dates[-1] = end_date + add_ending_hours\n",
    "\n",
    "        parsed_dates = []\n",
    "\n",
    "        for i in range(len(start_dates)):\n",
    "            \n",
    "            \n",
    "            parsed_dates.append(','.join([start_dates[i].strftime('%Y-%m-%dT%H:%M:%SZ'), ending_dates[i].strftime('%Y-%m-%dT%H:%M:%SZ')]))\n",
    "        return parsed_dates\n",
    "\n",
    "\n",
    "# find hls tiles given a point\n",
    "\n",
    "def find_hls_tiles(line_geo=False, band=False, limit=False, collections = ['HLSL30.v2.0', 'HLSS30.v2.0'], date_range = False):\n",
    "\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "    catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     x, y = point[0], point[1]\n",
    "    #     # print(x,y)\n",
    "    # except TypeError:\n",
    "    #     print(\"Point must be in the form of [lat,lon]\")\n",
    "    #     raise\n",
    "\n",
    "    # point = geopandas.points_from_xy([x],[y])\n",
    "    # point = point[0]\n",
    "\n",
    "    # date_range = '2017-01-01T00:00:00Z/2018-12-31T23:59:59Z'\n",
    "    if date_range == False:\n",
    "# ['2020-01-01:00:00:00Z', '..']\n",
    "        # search = catalog.search(\n",
    "        #     collections=collections, intersects = line_geo, datetime=date_range.replace(',', '/'))\n",
    "        raise ValueError('Please supply a date for ssc...')\n",
    "    else:\n",
    "        all_temporal_ranges = generate_time_search(date_range)\n",
    "        links = []\n",
    "        for i in all_temporal_ranges:\n",
    "            search = catalog.search(\n",
    "                collections=collections, intersects = line_geo, datetime=i.replace(',', '/'))\n",
    "\n",
    "\n",
    "            # print(f'{search.matched()} Tiles Found...')\n",
    "\n",
    "\n",
    "            item_collection = search.get_all_items()\n",
    "\n",
    "            if limit:\n",
    "                item_collection = item_collection[:limit]\n",
    "\n",
    "            if band:\n",
    "                if type(band) == list:\n",
    "                    for i in item_collection:\n",
    "                        for b in band:\n",
    "                            link = i.assets[b].href\n",
    "                            # print(link)\n",
    "                            links.append(link)\n",
    "                \n",
    "                else:\n",
    "                    for i in item_collection:\n",
    "                        link = i.assets[band].href\n",
    "                        links.append(link)\n",
    "            \n",
    "            else:\n",
    "                for i in item_collection:\n",
    "                    # print(i.assets)\n",
    "                    for key in i.assets:\n",
    "                        if key.startswith('B'):\n",
    "                            # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "                            link = i.assets[key].href\n",
    "\n",
    "                            # print(link)\n",
    "                            links.append(link)\n",
    "\n",
    "        return links\n",
    "\n",
    "def find_download_links_for_reach_tiles(data_dir, reach_id, cont, temporal_range):\n",
    "    try:\n",
    "        lat_list, lon_list = get_reach_node_cords(data_dir,reach_id, cont)\n",
    "        \n",
    "\n",
    "        df = pd.DataFrame(columns=['x', 'y'])\n",
    "        df['x'] = lat_list[:5]\n",
    "        df['y'] = lon_list[:5]\n",
    "        df['ID'] = reach_id\n",
    "        geometry = [Point(xy) for xy in zip(df.x, df.y)]\n",
    "\n",
    "\n",
    "\n",
    "        geo_df = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "        geo_df2 = geo_df.groupby(['ID'])['geometry'].apply(lambda x: LineString(x.tolist()))\n",
    "        geo_df2 = gpd.GeoDataFrame(geo_df2, geometry='geometry')\n",
    "        line_geo = list(geo_df2.geometry.unique())[0]\n",
    "        links = find_hls_tiles(line_geo=line_geo, date_range=temporal_range)\n",
    "\n",
    "        outpath = '/storage/data/ssc_matchup/'\n",
    "\n",
    "        with open(os.path.join(outpath,f'{reach_id}.json'), 'w') as f:\n",
    "            json.dump(links, f)\n",
    "            link = []\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        links = ['foo']\n",
    "        print('error on ', reach_id)\n",
    "        print(e)\n",
    "\n",
    "    return list(set(links))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_reach_node_cords(sword_path, reach_id, cont):\n",
    "\n",
    "    lat_list, lon_list = [], []\n",
    "\n",
    "    # sword_fp = os.path.join(data_dir, f'{cont.lower()}_sword_v15.nc')\n",
    "    # print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "\n",
    "    rootgrp = ncf.Dataset(sword_path, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "    node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "    if len(node_ids_indexes[0])!=0:\n",
    "        for y in node_ids_indexes[0]:\n",
    "\n",
    "            lat = float(rootgrp.groups['nodes'].variables['x'][y].data.astype('U'))\n",
    "            lon = float(rootgrp.groups['nodes'].variables['y'][y].data.astype('U'))\n",
    "            # all_nodes.append([lat,lon])\n",
    "            lat_list.append(lat)\n",
    "            lon_list.append(lon)\n",
    "\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    # print(f'Found {len(all_nodes)} nodes...')\n",
    "    return lat_list, lon_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# all_links = find_download_links_for_reach_tiles('/home/confluence/data/mnt/input/sword',23216000521)\n",
    "# print(len(all_links))\n",
    "\n",
    "\n",
    "\n",
    "def ssc_process_continent(reach_ids, cont, data_dir, temporal_range):\n",
    "\n",
    "\n",
    "    pool = Pool(processes=7)              # start 4 worker processes\n",
    "    result = pool.starmap(find_download_links_for_reach_tiles, zip(repeat(data_dir), reach_ids, repeat(cont), repeat(temporal_range)))\n",
    "    # cnt = 0\n",
    "    # for i in result:\n",
    "    #     for x in i:\n",
    "    #         cnt += 1\n",
    "\n",
    "    pool.close()\n",
    "\n",
    "    flatten_list = list(chain.from_iterable(result))\n",
    "    flatten_list = list(set(flatten_list))\n",
    "    no_bands = list(set([i[:-10] for i in flatten_list]))\n",
    "    print(f'Found {len(no_bands)} scenes for {cont}...')\n",
    "    return no_bands\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on  74262200221\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200221.json/w'\n",
      "error on  74262300371\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300371.json/w'\n",
      "error on  74262400111\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262400111.json/w'\n",
      "error on  74262600213\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262600213.json/w'\n",
      "error on  74262700303\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262700303.json/w'\n",
      "error on  74262300864\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300864.json/w'\n",
      "error on  74262200231\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200231.json/w'\n",
      "error on  74262300383\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300383.json/w'\n",
      "error on  74262400121\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262400121.json/w'\n",
      "error on  74262600223\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262600223.json/w'\n",
      "error on  74262300873\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300873.json/w'\n",
      "error on  74262700314\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262700314.json/w'\n",
      "error on  74261000011\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000011.json/w'\n",
      "error on  74262200241\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200241.json/w'\n",
      "error on  74262300883\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300883.json/w'\n",
      "error on  74262300391\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300391.json/w'\n",
      "error on  74262600253\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262600253.json/w'\n",
      "error on  74262400131\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262400131.json/w'\n",
      "error on  74262400144\n",
      "{\"message\":\"If the problem persists please contact cmr-support@earthdata.nasa.gov\",\"errors\":[\"An unexpected error occurred. We have been alerted and are working to resolve the problem.\",\"connect EMFILE 10.8.19.106:80 - Local (undefined:undefined)\"]}\n",
      "error on  74262400153\n",
      "{\"message\":\"If the problem persists please contact cmr-support@earthdata.nasa.gov\",\"errors\":[\"An unexpected error occurred. We have been alerted and are working to resolve the problem.\",\"getaddrinfo EMFILE internal-cmr-services-prod-1915322733.us-east-1.elb.amazonaws.com\"]}\n",
      "error on  74261000021\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000021.json/w'\n",
      "error on  74262400161\n",
      "\n",
      "error on  74262300891\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300891.json/w'\n",
      "error on  74262700323\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262700323.json/w'\n",
      "error on  74262300901\n",
      "\n",
      "error on  74262200251\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200251.json/w'\n",
      "error on  74262300401\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300401.json/w'\n",
      "error on  74262300911\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300911.json/w'\n",
      "error on  74261000034\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000034.json/w'\n",
      "error on  74262200261\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200261.json/w'\n",
      "error on  74262700331\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262700331.json/w'\n",
      "error on  74262300921\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300921.json/w'\n",
      "error on  74262300411\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300411.json/w'\n",
      "error on  74262600283\n",
      "<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "error on  74261000041\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000041.json/w'\n",
      "error on  74262200271\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200271.json/w'\n",
      "error on  74262400174\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262400174.json/w'\n",
      "error on  74262300934\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300934.json/w'\n",
      "error on  74262300421\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300421.json/w'\n",
      "error on  74262200284\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200284.json/w'error on \n",
      " 74262700343\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262700343.json/w'\n",
      "error on  74262600301\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262600301.json/w'\n",
      "error on  74261000051\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000051.json/w'\n",
      "error on  74262300943\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300943.json/w'\n",
      "error on  74262200291\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200291.json/w'\n",
      "error on  74262300433\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300433.json/w'\n",
      "error on  74261000061\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000061.json/w'\n",
      "error on  74262700351\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262700351.json/w'\n",
      "error on  74262600314\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262600314.json/w'\n",
      "error on  74262300963\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300963.json/w'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     reach_ids \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m reach_ids \u001b[39m=\u001b[39m [i[\u001b[39m'\u001b[39m\u001b[39mreach_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m reach_ids]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m no_bands \u001b[39m=\u001b[39m ssc_process_continent(reach_ids, cont, data_dir, temporal_range)\n",
      "\u001b[1;32m/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=212'>213</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mssc_process_continent\u001b[39m(reach_ids, cont, data_dir, temporal_range):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=215'>216</a>\u001b[0m     pool \u001b[39m=\u001b[39m Pool(processes\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)              \u001b[39m# start 4 worker processes\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=216'>217</a>\u001b[0m     result \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mstarmap(find_download_links_for_reach_tiles, \u001b[39mzip\u001b[39;49m(repeat(data_dir), reach_ids, repeat(cont), repeat(temporal_range)))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=217'>218</a>\u001b[0m     \u001b[39m# cnt = 0\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=218'>219</a>\u001b[0m     \u001b[39m# for i in result:\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=219'>220</a>\u001b[0m     \u001b[39m#     for x in i:\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=220'>221</a>\u001b[0m     \u001b[39m#         cnt += 1\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baws_dev/storage/repos/ssc_model_deployment/dev_notebooks/offline_hls_search_reaches_of_interest.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=222'>223</a>\u001b[0m     pool\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/ssc_deploy/lib/python3.9/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/ssc_deploy/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssc_deploy/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssc_deploy/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/ssc_deploy/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on  74262200301\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262200301.json/w'\n",
      "error on  74262400183\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262400183.json/w'\n",
      "error on  74261000074\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74261000074.json/w'\n",
      "error on  74262300443\n",
      "[Errno 2] No such file or directory: '/storage/data/ssc_matchup/74262300443.json/w'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "temporal_range = \"2023-01-01T00:00:00Z,2024-04-25T23:59:59Z\"\n",
    "cont = 'NA'\n",
    "data_dir = '/storage/data/hpc/mnt/input/sword/na_sword_v16.nc'\n",
    "\n",
    "with open(os.path.join('/storage/data/hpc/mnt/', 'input', 'reaches.json')) as f:\n",
    "    reach_ids = json.load(f)\n",
    "\n",
    "reach_ids = [i['reach_id'] for i in reach_ids]\n",
    "\n",
    "\n",
    "no_bands = ssc_process_continent(reach_ids, cont, data_dir, temporal_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travis -  run hls matchup and give you a list of tiles\n",
    "# Travis - list of reach IDs and dates you have discharge\n",
    "# Luisa - check for overlap between days we have discharge for a reach and the hls tiles\n",
    "# Luisa - list of reaches and tiles that overlap\n",
    "# Travis - preprocess them\n",
    "# Luisa - runs ANN, analyses, and so on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssc_deploy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
