{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/02_Data_Discovery_CMR-STAC_API.html\n",
    "\n",
    "from pystac_client import Client  \n",
    "from collections import defaultdict    \n",
    "import json\n",
    "import geopandas\n",
    "# import geoviews as gv\n",
    "from cartopy import crs\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hls tiles given a point\n",
    "\n",
    "def find_hls_tiles(point=False, band=False, limit=False, collections = ['HLSL30.v2.0', 'HLSS30.v2.0'], date_range = False):\n",
    "\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "    catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        x, y = point[0], point[1]\n",
    "        # print(x,y)\n",
    "    except TypeError:\n",
    "        print(\"Point must be in the form of [lat,lon]\")\n",
    "        raise\n",
    "\n",
    "    point = geopandas.points_from_xy([x],[y])\n",
    "    point = point[0]\n",
    "\n",
    "    # date_range = '2017-01-01T00:00:00Z/2018-12-31T23:59:59Z'\n",
    "\n",
    "    # JOHN - THIS IS WHERE YOU WOULD ADD IN SEARCH PARAMETERS\n",
    "    if date_range:\n",
    "# ['2020-01-01:00:00:00Z', '..']\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point, datetime=date_range, limit=limit)\n",
    "    else:\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point)\n",
    "\n",
    "\n",
    "\n",
    "    # print(f'{search.matched()} Tiles Found...')\n",
    "\n",
    "\n",
    "    item_collection = search.get_all_items()\n",
    "\n",
    "    if limit:\n",
    "        item_collection = item_collection[:limit]\n",
    "\n",
    "    if band:\n",
    "        links = []\n",
    "        if type(band) == list:\n",
    "            for i in item_collection:\n",
    "                for b in band:\n",
    "                    link = i.assets[b].href\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "        \n",
    "        else:\n",
    "            for i in item_collection:\n",
    "                link = i.assets[band].href\n",
    "                links.append(link)\n",
    "    \n",
    "    else:\n",
    "        links =[]\n",
    "        for i in item_collection:\n",
    "            # print(i.assets)\n",
    "            for key in i.assets:\n",
    "                if key.startswith('B'):\n",
    "                    # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "                    link = i.assets[key].href\n",
    "\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the nodes\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_reach_nodes(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*v15.nc'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "                node_id = str(rootgrp.groups['nodes'].variables['node_id'][y].data.astype('U'))\n",
    "                all_nodes.append(node_id)\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(set(all_nodes))} nodes...')\n",
    "    return list(set(all_nodes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get_reach_nodes(data_dir,74270100221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the lat/lon points of all nodes\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "def get_reach_node_cords(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*v15.nc'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "\n",
    "                lat = str(rootgrp.groups['nodes'].variables['x'][y].data.astype('U'))\n",
    "                lon = str(rootgrp.groups['nodes'].variables['y'][y].data.astype('U'))\n",
    "                all_nodes.append([lat,lon])\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(all_nodes)} nodes...')\n",
    "    return all_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, create download links for any hls tiles that intersect the nodes in the reach\n",
    "\n",
    "\n",
    "def find_download_links_for_reach_tiles(data_dir, reach_id):\n",
    "    node_coords = get_reach_node_cords(data_dir,reach_id)\n",
    "    all_links = []\n",
    "    for i in node_coords:\n",
    "        print(i)\n",
    "        links = find_hls_tiles(i,limit=1)\n",
    "        print(links)\n",
    "        all_links.extend(links)\n",
    "\n",
    "    return list(set(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, LineString, MultiPoint, Point\n",
    "\n",
    "def find_node_tiles(all_points, all_nodes, gdf):\n",
    "    tiles_dict = {}\n",
    "    for index, i in enumerate(all_points):\n",
    "        point = Point(i[0],i[1])\n",
    "        sentinal_tiles = gdf[gdf['geometry'].covers(point)]['Name'].tolist()\n",
    "        tiles_dict[all_nodes[index]] = {'point':point, 'sentinal_tile':sentinal_tiles}\n",
    "    return tiles_dict\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shpfile overlap\n",
    "\n",
    "\n",
    "data_dir = '/home/travis/data/10-24/mnt/input/sword'\n",
    "reach_id = 23216000521\n",
    "\n",
    "# all_links =  find_download_links_for_reach_tiles(data_dir, reach_id)\n",
    "all_points = get_reach_node_cords(data_dir, reach_id);all_points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = get_reach_nodes(data_dir, reach_id);all_nodes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas \n",
    "import fiona\n",
    "import glob\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.read_file('/home/travis/data/Sentinel-2-Shapefile-Index/sentinel_2_index_shapefile.shp');gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_node_tiles(all_points[:10], all_nodes, gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, LineString, MultiPoint, Point\n",
    "\n",
    "point = Point('45.02741982760003','0.22797328583233897');point\n",
    "point = Point('0.22797328583233897','45.02741982760003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[gdf['geometry'].covers(point)]['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for those tiles in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client  \n",
    "from shapely.geometry import Polygon, LineString, MultiPoint, Point\n",
    "\n",
    "\n",
    "collections = ['HLSL30.v2.0', 'HLSS30.v2.0']\n",
    "\n",
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "point = Point('0.22797328583233897','45.02741982760003')\n",
    "search = catalog.search(collections=collections, intersects = point, datetime='2018-01-02T00:00:00Z/2018-02-02T23:59:59Z')\n",
    "# search = catalog.search(collections=collections, datetime='2018-01-02T00:00:00Z/2018-01-02T23:59:59Z')   # date_range = '2018-01-01T00:00:00Z/2018-02-01T23:59:59Z')\n",
    "\n",
    "\n",
    "item_collection = search.item_collection()\n",
    "\n",
    "\n",
    "links =[]\n",
    "for i in item_collection:\n",
    "    # print(i.assets)\n",
    "    for key in i.assets:\n",
    "        if key.startswith('B'):\n",
    "            # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "            link = i.assets[key].href\n",
    "\n",
    "            # print(link)\n",
    "            links.append(link)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we pull all tiles from the last month and do overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as ncf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/home/travis/data/10-24/mnt/input/sword/na_sword_v15.nc'\n",
    "data = ncf.Dataset(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.read_file('/home/travis/data/Sentinel-2-Shapefile-Index/sentinel_2_index_shapefile.shp');gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a tile, loop through nodes, find overlap, make reaches\n",
    "\n",
    "# dict = {'tile_num' : \n",
    "#             {reach_id: \n",
    "#                 {'node_id':('lat','lon')}}}\n",
    "\n",
    "scene_name = 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T31TCK.2017003T104213.v2.0/HLS.L30.T31TCK.2017003T104213.v2.0.B05.tif'\n",
    "tile_name = scene_name.split('/')[3];tile_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes, find all the tiles for a reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf1bd4089eeb07bd42be11eba3fd4a0690dd46725eb70cb64f8b38092e2cddff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
